{"basics":{"name":"Dan Chen","label":"Research Fellow","image":"","email":"danchen@nus.edu.sg","phone":"+65 158-270-53862","url":"","summary":"Research Fellow at the School of Computing, National University of Singapore (NUS). I design energy-efficient, high-performance AI systems through software–hardware co-design, focusing on near-memory computing and specialized architectures for emerging AI workloads.","location":{"address":"","postalCode":"","city":"Singapore","countryCode":"SG","region":""},"profiles":[{"network":"Email","username":"danchen@nus.edu.sg","url":"mailto:danchen@nus.edu.sg"}]},"work":[{"name":"National University of Singapore (NUS), School of Computing","position":"Research Fellow","url":"https://www.comp.nus.edu.sg/","startDate":"2024-03-01","endDate":"","summary":"Working with Prof. Tulika Mitra on AI system acceleration and architectural optimization.","highlights":["Heterogeneous near-memory systems and specialized architectures for LLM/RAG acceleration.","Energy-efficient designs for sparse operators and graph workloads via software–hardware co-design."]}],"education":[{"institution":"Huazhong University of Science and Technology (HUST)","location":"Wuhan, China","url":"https://english.hust.edu.cn/","area":"Computer Science and Technology","studyType":"Ph.D.","startDate":"2018-09-01","endDate":"2024-03-01","score":"","courses":["Research focus: AI system acceleration, near-memory computing, and architectures for graph/sparse/LLM workloads.","Advisor: Prof. Hai Jin (IEEE/CCF Fellow)."]},{"institution":"North China Electric Power University (NCEPU)","location":"Beijing, China","url":"https://english.ncepu.edu.cn/","area":"Computer Science and Technology","studyType":"B.Eng.","startDate":"2014-09-01","endDate":"2018-06-01","score":"","courses":["Graduated first in major; direct admission to graduate studies."]}],"projects":[{"name":"Green AI — Near-Memory Architectures for LLM and RAG","summary":"Designed near-memory architectures for LLM and retrieval-augmented generation, achieving low energy and high performance.","highlights":["Developed specialized near-memory pipelines for LLM/RAG workloads.","Results published in TC and ISCA venues."],"startDate":"2024-03-01","endDate":"","url":""},{"name":"Graph Computing Accelerator Design","summary":"Core member at Zhejiang Lab Joint Graph Computing Research Center (~¥80M). Built frameworks and programming abstractions for graph computing accelerators.","highlights":["Led heterogeneous near-memory accelerator designs for HGNNs and dynamic graphs.","Contributions appeared in ISCA'23 and IPDPS'23."],"startDate":"2021-12-01","endDate":"2024-03-01","url":""},{"name":"Processing-in-Memory Systems for Graph Computing","summary":"National Key R&D Program “Cloud Computing and Big Data” (~¥40M).","highlights":["Designed general PIM offloading techniques ensuring accuracy across domains (IPDPS'22).","Built heterogeneous GPU+PIM platforms for GNN acceleration (TC)."],"startDate":"2018-05-01","endDate":"2022-01-01","url":""},{"name":"Parallel and Distributed Computing","summary":"National Natural Science Foundation Distinguished Young Project (~¥4M).","highlights":["Developed the first asynchronous dynamic graph processing system with >5× speedup over state of the art (SC'22)."],"startDate":"2019-01-01","endDate":"2022-12-01","url":""}],"awards":[{"title":"chip100 World Chip Contribution List","date":"2023-01-01","awarder":"","url":"","summary":"Recognized in the 2022–2023 chip100 list."},{"title":"China International “Internet+” Innovation & Entrepreneurship Competition — Gold Award","date":"2022-01-01","awarder":"","url":"","summary":""},{"title":"China Engineering Robotics Competition — Special Prize","date":"2017-01-01","awarder":"","url":"","summary":""},{"title":"Mathematical Contest in Modeling (MCM) — Meritorious Winner","date":"2017-01-01","awarder":"","url":"","summary":""}],"skills":[{"name":"AI System Acceleration","level":"","icon":"fa-solid fa-microchip","keywords":["Near-memory computing","LLM/RAG acceleration","Sparse operators","Graph analytics"]},{"name":"Software–Hardware Co-Design","level":"","icon":"fa-solid fa-code","keywords":["Heterogeneous architectures","Runtime and compiler co-optimization","Energy-efficient design"]}],"languages":[{"language":"Chinese","fluency":"Native speaker","icon":""},{"language":"English","fluency":"Fluent","icon":""}],"interests":[{"name":"AI acceleration and architecture","icon":"fa-solid fa-bolt","keywords":["Near-memory systems","Specialized accelerators","Graph and sparse workloads","LLM/RAG optimization"]}],"references":[]}